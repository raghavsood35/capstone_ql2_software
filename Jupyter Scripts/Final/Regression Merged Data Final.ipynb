{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model on Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats as stats\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cwdir = os.getcwd()\n",
    "# air = pd.read_csv(cwdir + \"\\\\Final Airfar Data for Midterm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car = pd.read_csv(cwdir + \"\\\\Final Car Rental Data for Midterm.csv\")\n",
    "#car = pd.read_csv(cwdir + \"\\\\car_withLOR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# air.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# air_lax = air[air[\"TO_AIRPORT\"] == \"LAX\"]\n",
    "# air_lax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car_lax = car[car[\"LOCATION\"] == \"LAX\"]\n",
    "# car_lax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = pd.merge(car_lax, air_lax,  how='left', left_on=['WEEK_NO','DAYOFWEEK(PDATE)'], right_on = ['EXTRACT(WEEK FROM DDATE)','DAYOFWEEK(DDATE)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged.to_csv(\"Merged Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run from here next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv(\"../../Data/Merged Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163416 entries, 0 to 163415\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Unnamed: 0                163416 non-null  int64  \n",
      " 1   LOCATION                  163416 non-null  object \n",
      " 2   AGENCY                    163416 non-null  object \n",
      " 3   WEEK_NO                   163416 non-null  int64  \n",
      " 4   DAYOFWEEK(PDATE)          163416 non-null  int64  \n",
      " 5   AVG(DAILY_FARE)           163416 non-null  float64\n",
      " 6   MIN(DAILY_FARE)           163416 non-null  float64\n",
      " 7   MAX(DAILY_FARE)           163416 non-null  float64\n",
      " 8   MEDIAN(DAILY_FARE)        163416 non-null  float64\n",
      " 9   STDDEV(DAILY_FARE)        163416 non-null  float64\n",
      " 10  NO_RECORDS_x              163416 non-null  int64  \n",
      " 11  TO_AIRPORT                163416 non-null  object \n",
      " 12  CXR                       163416 non-null  object \n",
      " 13  FROM_AIRPORT              163416 non-null  object \n",
      " 14  EXTRACT(WEEK FROM DDATE)  163416 non-null  int64  \n",
      " 15  DAYOFWEEK(DDATE)          163416 non-null  int64  \n",
      " 16  AVG(FARE)                 163416 non-null  float64\n",
      " 17  MIN(FARE)                 163416 non-null  float64\n",
      " 18  MAX(FARE)                 163416 non-null  float64\n",
      " 19  MEDIAN(FARE)              163416 non-null  float64\n",
      " 20  STDDEV(FARE)              162424 non-null  float64\n",
      " 21  NO_RECORDS_y              163416 non-null  int64  \n",
      " 22  DISTANCE                  163416 non-null  int64  \n",
      "dtypes: float64(10), int64(8), object(5)\n",
      "memory usage: 28.7+ MB\n"
     ]
    }
   ],
   "source": [
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>AGENCY</th>\n",
       "      <th>WEEK_NO</th>\n",
       "      <th>DAYOFWEEK(PDATE)</th>\n",
       "      <th>AVG(DAILY_FARE)</th>\n",
       "      <th>MIN(DAILY_FARE)</th>\n",
       "      <th>MAX(DAILY_FARE)</th>\n",
       "      <th>MEDIAN(DAILY_FARE)</th>\n",
       "      <th>STDDEV(DAILY_FARE)</th>\n",
       "      <th>...</th>\n",
       "      <th>FROM_AIRPORT</th>\n",
       "      <th>EXTRACT(WEEK FROM DDATE)</th>\n",
       "      <th>DAYOFWEEK(DDATE)</th>\n",
       "      <th>AVG(FARE)</th>\n",
       "      <th>MIN(FARE)</th>\n",
       "      <th>MAX(FARE)</th>\n",
       "      <th>MEDIAN(FARE)</th>\n",
       "      <th>STDDEV(FARE)</th>\n",
       "      <th>NO_RECORDS_y</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAX</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.560914</td>\n",
       "      <td>20.521111</td>\n",
       "      <td>342.405</td>\n",
       "      <td>79.508889</td>\n",
       "      <td>38.522142</td>\n",
       "      <td>...</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>278.100000</td>\n",
       "      <td>243.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>66.108413</td>\n",
       "      <td>10</td>\n",
       "      <td>2469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LAX</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.560914</td>\n",
       "      <td>20.521111</td>\n",
       "      <td>342.405</td>\n",
       "      <td>79.508889</td>\n",
       "      <td>38.522142</td>\n",
       "      <td>...</td>\n",
       "      <td>OGG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>589.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>42.426407</td>\n",
       "      <td>2</td>\n",
       "      <td>2483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LAX</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.560914</td>\n",
       "      <td>20.521111</td>\n",
       "      <td>342.405</td>\n",
       "      <td>79.508889</td>\n",
       "      <td>38.522142</td>\n",
       "      <td>...</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>245.500000</td>\n",
       "      <td>178.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>245.5</td>\n",
       "      <td>95.459415</td>\n",
       "      <td>2</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LAX</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.560914</td>\n",
       "      <td>20.521111</td>\n",
       "      <td>342.405</td>\n",
       "      <td>79.508889</td>\n",
       "      <td>38.522142</td>\n",
       "      <td>...</td>\n",
       "      <td>PDX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>69.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>15.063966</td>\n",
       "      <td>14</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LAX</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.560914</td>\n",
       "      <td>20.521111</td>\n",
       "      <td>342.405</td>\n",
       "      <td>79.508889</td>\n",
       "      <td>38.522142</td>\n",
       "      <td>...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>251.229167</td>\n",
       "      <td>89.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>219.5</td>\n",
       "      <td>152.098266</td>\n",
       "      <td>48</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 LOCATION AGENCY  WEEK_NO  DAYOFWEEK(PDATE)  AVG(DAILY_FARE)  \\\n",
       "0           0      LAX     AL        1                 0        82.560914   \n",
       "1           1      LAX     AL        1                 0        82.560914   \n",
       "2           2      LAX     AL        1                 0        82.560914   \n",
       "3           3      LAX     AL        1                 0        82.560914   \n",
       "4           4      LAX     AL        1                 0        82.560914   \n",
       "\n",
       "   MIN(DAILY_FARE)  MAX(DAILY_FARE)  MEDIAN(DAILY_FARE)  STDDEV(DAILY_FARE)  \\\n",
       "0        20.521111          342.405           79.508889           38.522142   \n",
       "1        20.521111          342.405           79.508889           38.522142   \n",
       "2        20.521111          342.405           79.508889           38.522142   \n",
       "3        20.521111          342.405           79.508889           38.522142   \n",
       "4        20.521111          342.405           79.508889           38.522142   \n",
       "\n",
       "   ...  FROM_AIRPORT EXTRACT(WEEK FROM DDATE) DAYOFWEEK(DDATE)   AVG(FARE)  \\\n",
       "0  ...           JFK                        1                0  278.100000   \n",
       "1  ...           OGG                        1                0  619.000000   \n",
       "2  ...           ORD                        1                0  245.500000   \n",
       "3  ...           PDX                        1                0   94.000000   \n",
       "4  ...           SEA                        1                0  251.229167   \n",
       "\n",
       "   MIN(FARE)  MAX(FARE)  MEDIAN(FARE)  STDDEV(FARE)  NO_RECORDS_y  DISTANCE  \n",
       "0      243.0      429.0         243.0     66.108413            10      2469  \n",
       "1      589.0      649.0         619.0     42.426407             2      2483  \n",
       "2      178.0      313.0         245.5     95.459415             2      1741  \n",
       "3       69.0      119.0          99.0     15.063966            14       835  \n",
       "4       89.0      599.0         219.5    152.098266            48       955  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = [1,2,3,4]\n",
    "merged[\"weekend\"] = np.where(merged.iloc[:,4].isin(weekdays) == True, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163416 entries, 0 to 163415\n",
      "Data columns (total 63 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   AVG(DAILY_FARE)  163416 non-null  float64\n",
      " 1   NO_RECORDS_x     163416 non-null  int64  \n",
      " 2   AVG(FARE)        163416 non-null  float64\n",
      " 3   NO_RECORDS_y     163416 non-null  int64  \n",
      " 4   weekend          163416 non-null  int64  \n",
      " 5   AGENCY_ET        163416 non-null  uint8  \n",
      " 6   AGENCY_ZD        163416 non-null  uint8  \n",
      " 7   AGENCY_ZE        163416 non-null  uint8  \n",
      " 8   AGENCY_ZI        163416 non-null  uint8  \n",
      " 9   AGENCY_ZL        163416 non-null  uint8  \n",
      " 10  AGENCY_ZR        163416 non-null  uint8  \n",
      " 11  AGENCY_ZT        163416 non-null  uint8  \n",
      " 12  WEEK_NO_2        163416 non-null  uint8  \n",
      " 13  WEEK_NO_3        163416 non-null  uint8  \n",
      " 14  WEEK_NO_4        163416 non-null  uint8  \n",
      " 15  WEEK_NO_5        163416 non-null  uint8  \n",
      " 16  WEEK_NO_6        163416 non-null  uint8  \n",
      " 17  WEEK_NO_7        163416 non-null  uint8  \n",
      " 18  WEEK_NO_8        163416 non-null  uint8  \n",
      " 19  WEEK_NO_9        163416 non-null  uint8  \n",
      " 20  WEEK_NO_10       163416 non-null  uint8  \n",
      " 21  WEEK_NO_11       163416 non-null  uint8  \n",
      " 22  WEEK_NO_12       163416 non-null  uint8  \n",
      " 23  WEEK_NO_13       163416 non-null  uint8  \n",
      " 24  WEEK_NO_14       163416 non-null  uint8  \n",
      " 25  WEEK_NO_15       163416 non-null  uint8  \n",
      " 26  WEEK_NO_16       163416 non-null  uint8  \n",
      " 27  WEEK_NO_17       163416 non-null  uint8  \n",
      " 28  WEEK_NO_18       163416 non-null  uint8  \n",
      " 29  WEEK_NO_19       163416 non-null  uint8  \n",
      " 30  WEEK_NO_20       163416 non-null  uint8  \n",
      " 31  WEEK_NO_21       163416 non-null  uint8  \n",
      " 32  WEEK_NO_22       163416 non-null  uint8  \n",
      " 33  WEEK_NO_23       163416 non-null  uint8  \n",
      " 34  WEEK_NO_24       163416 non-null  uint8  \n",
      " 35  WEEK_NO_25       163416 non-null  uint8  \n",
      " 36  WEEK_NO_26       163416 non-null  uint8  \n",
      " 37  WEEK_NO_27       163416 non-null  uint8  \n",
      " 38  WEEK_NO_28       163416 non-null  uint8  \n",
      " 39  WEEK_NO_29       163416 non-null  uint8  \n",
      " 40  WEEK_NO_30       163416 non-null  uint8  \n",
      " 41  WEEK_NO_31       163416 non-null  uint8  \n",
      " 42  WEEK_NO_32       163416 non-null  uint8  \n",
      " 43  WEEK_NO_33       163416 non-null  uint8  \n",
      " 44  WEEK_NO_34       163416 non-null  uint8  \n",
      " 45  WEEK_NO_35       163416 non-null  uint8  \n",
      " 46  WEEK_NO_36       163416 non-null  uint8  \n",
      " 47  WEEK_NO_37       163416 non-null  uint8  \n",
      " 48  WEEK_NO_38       163416 non-null  uint8  \n",
      " 49  WEEK_NO_39       163416 non-null  uint8  \n",
      " 50  WEEK_NO_40       163416 non-null  uint8  \n",
      " 51  WEEK_NO_41       163416 non-null  uint8  \n",
      " 52  WEEK_NO_42       163416 non-null  uint8  \n",
      " 53  WEEK_NO_43       163416 non-null  uint8  \n",
      " 54  WEEK_NO_44       163416 non-null  uint8  \n",
      " 55  WEEK_NO_45       163416 non-null  uint8  \n",
      " 56  WEEK_NO_46       163416 non-null  uint8  \n",
      " 57  WEEK_NO_47       163416 non-null  uint8  \n",
      " 58  WEEK_NO_48       163416 non-null  uint8  \n",
      " 59  WEEK_NO_49       163416 non-null  uint8  \n",
      " 60  WEEK_NO_50       163416 non-null  uint8  \n",
      " 61  WEEK_NO_51       163416 non-null  uint8  \n",
      " 62  WEEK_NO_52       163416 non-null  uint8  \n",
      "dtypes: float64(2), int64(3), uint8(58)\n",
      "memory usage: 15.3 MB\n"
     ]
    }
   ],
   "source": [
    "merged_reg = merged.copy()\n",
    "\n",
    "#Dropped FROM_AIRPORT , DISTANCE , CXR\n",
    "#Added No_records_y ,  AVG(FARE) into regression --this will include Airfare as a feature for Care Fare prediction\n",
    "drop_columns = [\"FROM_AIRPORT\", \"DISTANCE\", \"CXR\",\"DAYOFWEEK(PDATE)\",\"Unnamed: 0\", \"LOCATION\", \"MIN(DAILY_FARE)\", \"MAX(DAILY_FARE)\", \"MEDIAN(DAILY_FARE)\",\"STDDEV(DAILY_FARE)\",\"TO_AIRPORT\", \"EXTRACT(WEEK FROM DDATE)\", \"DAYOFWEEK(DDATE)\", \"MIN(FARE)\",\"MAX(FARE)\", \"MEDIAN(FARE)\", \"STDDEV(FARE)\"]\n",
    "merged_reg.drop(columns = drop_columns , axis=1, inplace = True)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Group by everything except Label column\n",
    "merged_regression_group = merged_reg.groupby(list(merged_regression.columns[:-1]) , as_index=False)\n",
    "merged_regression_group.aggregate(np.mean)\n",
    "\n",
    "merged_regression = pd.DataFrame(merged_regression_group)\"\"\"\n",
    "merged_regression = pd.get_dummies(merged_reg,columns=['AGENCY' , \"WEEK_NO\"], drop_first=True)\n",
    "merged_regression.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163416 entries, 0 to 163415\n",
      "Data columns (total 63 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   NO_RECORDS_x    163416 non-null  int64  \n",
      " 1   AVG_FARE        163416 non-null  float64\n",
      " 2   NO_RECORDS_y    163416 non-null  int64  \n",
      " 3   weekend         163416 non-null  int64  \n",
      " 4   AGENCY_ET       163416 non-null  uint8  \n",
      " 5   AGENCY_ZD       163416 non-null  uint8  \n",
      " 6   AGENCY_ZE       163416 non-null  uint8  \n",
      " 7   AGENCY_ZI       163416 non-null  uint8  \n",
      " 8   AGENCY_ZL       163416 non-null  uint8  \n",
      " 9   AGENCY_ZR       163416 non-null  uint8  \n",
      " 10  AGENCY_ZT       163416 non-null  uint8  \n",
      " 11  WEEK_NO_2       163416 non-null  uint8  \n",
      " 12  WEEK_NO_3       163416 non-null  uint8  \n",
      " 13  WEEK_NO_4       163416 non-null  uint8  \n",
      " 14  WEEK_NO_5       163416 non-null  uint8  \n",
      " 15  WEEK_NO_6       163416 non-null  uint8  \n",
      " 16  WEEK_NO_7       163416 non-null  uint8  \n",
      " 17  WEEK_NO_8       163416 non-null  uint8  \n",
      " 18  WEEK_NO_9       163416 non-null  uint8  \n",
      " 19  WEEK_NO_10      163416 non-null  uint8  \n",
      " 20  WEEK_NO_11      163416 non-null  uint8  \n",
      " 21  WEEK_NO_12      163416 non-null  uint8  \n",
      " 22  WEEK_NO_13      163416 non-null  uint8  \n",
      " 23  WEEK_NO_14      163416 non-null  uint8  \n",
      " 24  WEEK_NO_15      163416 non-null  uint8  \n",
      " 25  WEEK_NO_16      163416 non-null  uint8  \n",
      " 26  WEEK_NO_17      163416 non-null  uint8  \n",
      " 27  WEEK_NO_18      163416 non-null  uint8  \n",
      " 28  WEEK_NO_19      163416 non-null  uint8  \n",
      " 29  WEEK_NO_20      163416 non-null  uint8  \n",
      " 30  WEEK_NO_21      163416 non-null  uint8  \n",
      " 31  WEEK_NO_22      163416 non-null  uint8  \n",
      " 32  WEEK_NO_23      163416 non-null  uint8  \n",
      " 33  WEEK_NO_24      163416 non-null  uint8  \n",
      " 34  WEEK_NO_25      163416 non-null  uint8  \n",
      " 35  WEEK_NO_26      163416 non-null  uint8  \n",
      " 36  WEEK_NO_27      163416 non-null  uint8  \n",
      " 37  WEEK_NO_28      163416 non-null  uint8  \n",
      " 38  WEEK_NO_29      163416 non-null  uint8  \n",
      " 39  WEEK_NO_30      163416 non-null  uint8  \n",
      " 40  WEEK_NO_31      163416 non-null  uint8  \n",
      " 41  WEEK_NO_32      163416 non-null  uint8  \n",
      " 42  WEEK_NO_33      163416 non-null  uint8  \n",
      " 43  WEEK_NO_34      163416 non-null  uint8  \n",
      " 44  WEEK_NO_35      163416 non-null  uint8  \n",
      " 45  WEEK_NO_36      163416 non-null  uint8  \n",
      " 46  WEEK_NO_37      163416 non-null  uint8  \n",
      " 47  WEEK_NO_38      163416 non-null  uint8  \n",
      " 48  WEEK_NO_39      163416 non-null  uint8  \n",
      " 49  WEEK_NO_40      163416 non-null  uint8  \n",
      " 50  WEEK_NO_41      163416 non-null  uint8  \n",
      " 51  WEEK_NO_42      163416 non-null  uint8  \n",
      " 52  WEEK_NO_43      163416 non-null  uint8  \n",
      " 53  WEEK_NO_44      163416 non-null  uint8  \n",
      " 54  WEEK_NO_45      163416 non-null  uint8  \n",
      " 55  WEEK_NO_46      163416 non-null  uint8  \n",
      " 56  WEEK_NO_47      163416 non-null  uint8  \n",
      " 57  WEEK_NO_48      163416 non-null  uint8  \n",
      " 58  WEEK_NO_49      163416 non-null  uint8  \n",
      " 59  WEEK_NO_50      163416 non-null  uint8  \n",
      " 60  WEEK_NO_51      163416 non-null  uint8  \n",
      " 61  WEEK_NO_52      163416 non-null  uint8  \n",
      " 62  AVG_DAILY_FARE  163416 non-null  float64\n",
      "dtypes: float64(2), int64(3), uint8(58)\n",
      "memory usage: 15.3 MB\n"
     ]
    }
   ],
   "source": [
    "#Rearranging columns\n",
    "merged_regression = merged_regression[[col for col in merged_regression.columns if col not in ['AVG(DAILY_FARE)']] + [ 'AVG(DAILY_FARE)']]\n",
    "\n",
    "\n",
    "#Removing paranthesis from the column names\n",
    "regression_columns = [ col.replace('(' , '_').replace(')' , '') for col in merged_regression.columns ]\n",
    "merged_regression.columns = regression_columns\n",
    "\n",
    "merged_regression.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (163416, 62)\n",
      "y (163416,)\n"
     ]
    }
   ],
   "source": [
    "# X = merged_regression.iloc[: , :-1]\n",
    "# print(\"X\" , X.shape)\n",
    "# y = merged_regression.iloc[:, -1]\n",
    "# print(\"y\" , y.shape)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163416, 63)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(datum):\n",
    "    #print(datum)\n",
    "    value = np.argmax(datum)\n",
    "    #print(\"value\",value)\n",
    "    value = int(value[8:])\n",
    "    #print(\"int value\",value)\n",
    "    \n",
    "    if value == 2:\n",
    "        #print(\"datum\",int(datum[0]))\n",
    "        if(int(datum[0]))==0:\n",
    "            value=1\n",
    "        else:\n",
    "            value=2         \n",
    "    \n",
    "    return value\n",
    "\n",
    "#a = [0,0,0,0]\n",
    "#decode(a)\n",
    "#decode(merged_regression.iloc[5000 , 11:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8effd5125be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5000\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-e7b74d2722c6>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(datum)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(\"value\",value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(\"int value\",value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "decode(merged_regression.iloc[5000 , 11:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = regression_columns[0]\n",
    "for xm in regression_columns[1:-1]:\n",
    "    x_features = x_features+'+'+xm\n",
    "x_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_columns[-1] + \"~\"+ x_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ols = smf.ols(formula= regression_columns[-1] + \"~\"+ x_features  , data = merged_regression ).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_param = abs(reg_ols.params)\n",
    "result_param.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,5))\n",
    "plt.plot(result_param)\n",
    "plt.xticks(rotation = 75)\n",
    "plt.legend([\"Coefficient values for features\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,7))\n",
    "\n",
    "#axes = fig.add_axes([0.1, 0.01, 0.5 ,0.8])\n",
    "#plt.scatter(reg_ols.pvalues.index , reg_ols.pvalues)\n",
    "plt.plot(reg_ols.pvalues)\n",
    "plt.xticks(rotation = 75)\n",
    "plt.yticks(np.arange(0, 1,0.1))\n",
    "plt.legend([\"p value of variables\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(reg_ols.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_ols.pvalues[reg_ols.pvalues>0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO_RECORDS_y    0.418647 -\n",
    "#CXR_HA          0.520692 -\n",
    "#WEEK_NO_3       0.064827 - Jan 14- Jan 28\n",
    "#WEEK_NO_17      0.898010 - Apr 22 - Apr 28\n",
    "#WEEK_NO_43      0.998704 - Oct 21 - Oct 27\n",
    "#WEEK_NO_45      0.94534  - Nov 4 - NOv 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,7))\n",
    "\n",
    "#axes = fig.add_axes([0.1, 0.01, 0.5 ,0.8])\n",
    "#plt.scatter(reg_ols.pvalues.index , reg_ols.pvalues)\n",
    "plt.plot(reg_ols.pvalues)\n",
    "plt.xticks(rotation = 75)\n",
    "plt.yticks(np.arange(0, 1,0.1))\n",
    "plt.legend([\"p value of variables\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_ols.predict(merged_regression.iloc[: , :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_regression['y_pred'] = [ yhat for yhat in y_pred]\n",
    "merged_regression.iloc[:5,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_regression.iloc[2 , 11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_regression.iloc[10000 , 11:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_regression['decode_week'] = 0\n",
    "#merged_regression.shape[0]\n",
    "for i in range(1000):\n",
    "    merged_regression.iloc[i,-1] = decode(merged_regression.iloc[i , 11:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_regression.iloc[999, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000,50000,1):\n",
    "    merged_regression.iloc[i,-1] = decode(merged_regression.iloc[i , 11:-3])\n",
    "merged_regression.iloc[9999,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50000,100000,1):\n",
    "    merged_regression.iloc[i,-1] = decode(merged_regression.iloc[i , 11:-3])\n",
    "merged_regression.iloc[99999,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100000,merged_regression.shape[0],1):\n",
    "    merged_regression.iloc[i,-1] = decode(merged_regression.iloc[i , 11:-3])\n",
    "merged_regression.iloc[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_merged_reg = merged_regression.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_merged_reg.drop(columns = result_merged_reg.columns[11:-3], inplace=True)\n",
    "result_merged_reg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_merged_reg.groupby(by = [\"decode_week\"])[\"y_pred\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(result_merged_reg.groupby(by = [\"decode_week\"])[\"y_pred\"].min())\n",
    "plt.plot(result_merged_reg.groupby(by = [\"decode_week\"])[\"AVG_DAILY_FARE\"].min(), color=\"green\")\n",
    "plt.xticks(range(53))\n",
    "plt.grid()\n",
    "#plt.plot( y=result_merged_reg['AVG_DAILY_FARE'])\n",
    "#plt.plot(merged_regression['y_pred'].rolling(window = 30) , color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#withWeekIndex = pd.merge(y_test, y_pred,  how='left', left_on=index, right_on = index)\n",
    "#y_test['y_pred']= [pred for pred in y_pred]\n",
    "#y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(merged.groupby(by = [\"WEEK_NO\"])[\"AVG(DAILY_FARE)\"].mean())\n",
    "plt.plot(merged.groupby(by = [\"WEEK_NO\"])[\"AVG(DAILY_FARE)\"].mean().rolling(window=3).mean(), 'k-', color=\"red\")\n",
    "plt.xticks(range(0,53))\n",
    "plt.grid()\n",
    "plt.legend([\"mean price per mile\", \"rolling average 3 weeks\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complete data\",merged_regression.shape)\n",
    "X = merged_regression.iloc[:, :-1]\n",
    "print(\"X features\" , X.shape)\n",
    "y = merged_regression[\"AVG_FARE\"]\n",
    "print( \"Y label\" , y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code below not used. Just for ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "print(\"Train RMSE error\", sqrt(mean_squared_error(y_train, reg.predict(X_train))))\n",
    "print(\"Test RMSE error\", sqrt(mean_squared_error(y_test, reg.predict(X_test))))\n",
    "print(\"Coefficients\")\n",
    "print(\"Intercept\" , reg.intercept_)\n",
    "for x, y in zip(X_train.columns.tolist(), reg.coef_):\n",
    "    print(x,round(y,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Lasso()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Train RMSE error\", sqrt(mean_squared_error(y_train, clf.predict(X_train))))\n",
    "print(\"Test RMSE error\", sqrt(mean_squared_error(y_test, clf.predict(X_test))))\n",
    "print(\"Coefficients\")\n",
    "for x, y in zip(X_train.columns.tolist(), clf.coef_):\n",
    "    print(x,round(y,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
