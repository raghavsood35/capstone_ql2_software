{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = pd.read_csv(\"../../Data/classification_data.csv\")\n",
    "airline_features = pd.read_csv(\"../../Data/new_airfare_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old preprocessing from Car Rental Classification_v2\n",
    "# classification_data.drop(columns = \"Unnamed: 0\", inplace = True)\n",
    "airline_features[\"DDATE\"] = pd.to_datetime(airline_features[\"DDATE\"], format='%Y-%m-%d')\n",
    "airline_features[\"DDATE_YEAR\"] = pd.DatetimeIndex(airline_features[\"DDATE\"]).year\n",
    "airline_features[\"DDATE_MONTH\"] = pd.DatetimeIndex(airline_features[\"DDATE\"]).month\n",
    "airline_features[\"DDATE_DATE\"] = pd.DatetimeIndex(airline_features[\"DDATE\"]).day\n",
    "airline_features.drop(columns = \"DDATE\", inplace = True)\n",
    "\n",
    "all_classification_data = pd.merge(classification_data, airline_features, how='left',\n",
    "                                   left_on=['PICKUP_DATE_YEAR','PICKUP_DATE_MONTH', 'PICKUP_DATE_DATE'], \n",
    "                                   right_on = ['DDATE_YEAR','DDATE_MONTH', 'DDATE_DATE'])\n",
    "\n",
    "all_classification_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_BEFORE_DAYS</th>\n",
       "      <th>HOLIDAY</th>\n",
       "      <th>HOLIDAY AFTER</th>\n",
       "      <th>HOLIDAY BEFORE</th>\n",
       "      <th>WEEKEND</th>\n",
       "      <th>CHANGE</th>\n",
       "      <th>PICKUP_DATE_YEAR</th>\n",
       "      <th>PICKUP_DATE_MONTH</th>\n",
       "      <th>PICKUP_DATE_DATE</th>\n",
       "      <th>OUTSIPP_economy</th>\n",
       "      <th>...</th>\n",
       "      <th>price_per_mile</th>\n",
       "      <th>total_fluc_50</th>\n",
       "      <th>total_fluc_70</th>\n",
       "      <th>total_fluc_120</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>trend</th>\n",
       "      <th>DDATE_YEAR</th>\n",
       "      <th>DDATE_MONTH</th>\n",
       "      <th>DDATE_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.137476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.165880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1.185111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No change</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-1.144296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Increase</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.258120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AVG_BEFORE_DAYS  HOLIDAY  HOLIDAY AFTER  HOLIDAY BEFORE  WEEKEND  \\\n",
       "37         3.137476        0              0               0        0   \n",
       "38        -0.165880        0              0               0        0   \n",
       "39        -1.185111        0              0               0        0   \n",
       "40        -1.144296        0              0               0        0   \n",
       "41         0.258120        0              0               0        0   \n",
       "\n",
       "       CHANGE  PICKUP_DATE_YEAR  PICKUP_DATE_MONTH  PICKUP_DATE_DATE  \\\n",
       "37   Decrease              2018                  2                 1   \n",
       "38   Decrease              2018                  2                 1   \n",
       "39  No change              2018                  2                 1   \n",
       "40   Increase              2018                  2                 1   \n",
       "41   Decrease              2018                  2                 1   \n",
       "\n",
       "    OUTSIPP_economy  ...  price_per_mile  total_fluc_50  total_fluc_70  \\\n",
       "37                0  ...        0.104127            0.0            0.0   \n",
       "38                0  ...        0.104127            0.0            0.0   \n",
       "39                0  ...        0.104127            0.0            0.0   \n",
       "40                0  ...        0.104127            0.0            0.0   \n",
       "41                0  ...        0.104127            0.0            0.0   \n",
       "\n",
       "    total_fluc_120  avg_price  pct_change     trend  DDATE_YEAR  DDATE_MONTH  \\\n",
       "37             0.0   0.104127         0.0  Decrease      2018.0          2.0   \n",
       "38             0.0   0.104127         0.0  Decrease      2018.0          2.0   \n",
       "39             0.0   0.104127         0.0  Decrease      2018.0          2.0   \n",
       "40             0.0   0.104127         0.0  Decrease      2018.0          2.0   \n",
       "41             0.0   0.104127         0.0  Decrease      2018.0          2.0   \n",
       "\n",
       "   DDATE_DATE  \n",
       "37        1.0  \n",
       "38        1.0  \n",
       "39        1.0  \n",
       "40        1.0  \n",
       "41        1.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classification_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AVG_BEFORE_DAYS',\n",
       " 'HOLIDAY',\n",
       " 'HOLIDAY AFTER',\n",
       " 'HOLIDAY BEFORE',\n",
       " 'WEEKEND',\n",
       " 'CHANGE',\n",
       " 'PICKUP_DATE_YEAR',\n",
       " 'PICKUP_DATE_MONTH',\n",
       " 'PICKUP_DATE_DATE',\n",
       " 'OUTSIPP_economy',\n",
       " 'OUTSIPP_luxury',\n",
       " 'OUTSIPP_midrange',\n",
       " 'OUTSIPP_premium',\n",
       " 'price_per_mile',\n",
       " 'total_fluc_50',\n",
       " 'total_fluc_70',\n",
       " 'total_fluc_120',\n",
       " 'avg_price',\n",
       " 'pct_change',\n",
       " 'trend',\n",
       " 'DDATE_YEAR',\n",
       " 'DDATE_MONTH',\n",
       " 'DDATE_DATE']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classification_data.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min train date: 201802\n",
      "Max train date: 201907\n",
      "\n",
      "Min test date: 201907\n",
      "Max test date: 202001\n"
     ]
    }
   ],
   "source": [
    "# Dropping not required columns\n",
    "drop_columns = [\"DDATE_YEAR\", \"DDATE_MONTH\", \"DDATE_DATE\", \"trend\", \"price_per_mile\", \"avg_price\"]\n",
    "ml_data = all_classification_data.copy()\n",
    "ml_data.drop(columns = drop_columns, inplace = True)\n",
    "classification_columns = [x for x in ml_data.columns.to_list() if x != \"CHANGE\"]\n",
    "X = ml_data[classification_columns]\n",
    "y = ml_data[\"CHANGE\"]\n",
    "\n",
    "X_train = X[:int(X.shape[0]*0.7)]\n",
    "X_test = X[int(X.shape[0]*0.7):]\n",
    "y_train = y[:int(X.shape[0]*0.7)]\n",
    "y_test = y[int(X.shape[0]*0.7):]\n",
    "\n",
    "# Checking correct sort order for train test splits\n",
    "print(\"Min train date:\", min(X_train[\"PICKUP_DATE_YEAR\"]*100 + X_train[\"PICKUP_DATE_MONTH\"]))\n",
    "print(\"Max train date:\", max(X_train[\"PICKUP_DATE_YEAR\"]*100 + X_train[\"PICKUP_DATE_MONTH\"]))\n",
    "print()\n",
    "print(\"Min test date:\", min(X_test[\"PICKUP_DATE_YEAR\"]*100 + X_test[\"PICKUP_DATE_MONTH\"]))\n",
    "print(\"Max test date:\", max(X_test[\"PICKUP_DATE_YEAR\"]*100 + X_test[\"PICKUP_DATE_MONTH\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, balanced_accuracy_score, classification_report\n",
    "                             ,roc_curve, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for default Gradient Boost  0.6546848013816926\n",
      "Test Accuracy for default Gradient Boost  0.44289132351089283\n",
      "\n",
      "Training Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.68      0.62      0.65      5689\n",
      "    Increase       0.73      0.62      0.67      5682\n",
      "   No change       0.60      0.71      0.65      7157\n",
      "\n",
      "    accuracy                           0.65     18528\n",
      "   macro avg       0.67      0.65      0.66     18528\n",
      "weighted avg       0.66      0.65      0.66     18528\n",
      "\n",
      "\n",
      "Test Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.41      0.26      0.32      2509\n",
      "    Increase       0.35      0.56      0.43      1925\n",
      "   No change       0.55      0.51      0.53      3507\n",
      "\n",
      "    accuracy                           0.44      7941\n",
      "   macro avg       0.44      0.44      0.43      7941\n",
      "weighted avg       0.46      0.44      0.44      7941\n",
      "\n",
      "CPU times: user 6.31 s, sys: 74.4 ms, total: 6.39 s\n",
      "Wall time: 6.42 s\n"
     ]
    }
   ],
   "source": [
    "grad = GradientBoostingClassifier()\n",
    "grad.fit(X_train, y_train)\n",
    "grad_pred = grad.predict(X_test)\n",
    "print(\"Training Accuracy for default Gradient Boost \",accuracy_score(y_train,grad.predict(X_train)))\n",
    "print(\"Test Accuracy for default Gradient Boost \",accuracy_score(y_test,grad_pred))\n",
    "print()\n",
    "print(\"Training Classification report\\n\", classification_report(y_train,grad.predict(X_train)))\n",
    "print()\n",
    "print(\"Test Classification report\\n\", classification_report(y_test, grad_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5400 candidates, totalling 27000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 21.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 40.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 46.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 51.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 63.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed: 71.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 78.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 91.0min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 99.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed: 107.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 123.6min\n",
      "[Parallel(n_jobs=-1)]: Done 22034 tasks      | elapsed: 132.8min\n",
      "[Parallel(n_jobs=-1)]: Done 24184 tasks      | elapsed: 148.2min\n",
      "[Parallel(n_jobs=-1)]: Done 26434 tasks      | elapsed: 157.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 6s, sys: 12 s, total: 3min 18s\n",
      "Wall time: 2h 39min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 27000 out of 27000 | elapsed: 159.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no_c...\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 0.1, 0.2, 0.4, 0.5],\n",
       "                         'min_samples_split': [2, 0.1, 0.3, 0.5, 0.8, 1.0],\n",
       "                         'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 200,\n",
       "                                          400]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Refer - https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae\n",
    "grad_grid = GradientBoostingClassifier()\n",
    "\n",
    "# Setting grid parameters\n",
    "# loss can only be deviance as exponential takes only 2 classes\n",
    "learning_rate = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200, 400]\n",
    "min_samples_split = [2, 0.1, 0.3, 0.5, 0.8, 1.0]\n",
    "min_samples_leaf = [1, 0.1, 0.2, 0.4, 0.5]\n",
    "max_features = [\"auto\", \"sqrt\" ,\"log2\"]\n",
    "\n",
    "\n",
    "parameters = dict(learning_rate = learning_rate, n_estimators = n_estimators,\n",
    "                  min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf,\n",
    "                max_features = max_features)\n",
    "\n",
    "gridF = GridSearchCV(estimator = grad_grid, param_grid = parameters, cv = 5, verbose = 1, scoring = \"accuracy\",\n",
    "                      n_jobs = -1)\n",
    "gridF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 0.4,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 2}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters\n",
    "gridF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for default Gradient Boost  0.41294257340241797\n",
      "Test Accuracy for default Gradient Boost  0.47676615035889686\n",
      "\n",
      "Training Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.42      0.18      0.25      5689\n",
      "    Increase       0.31      0.16      0.21      5682\n",
      "   No change       0.44      0.80      0.56      7157\n",
      "\n",
      "    accuracy                           0.41     18528\n",
      "   macro avg       0.39      0.38      0.34     18528\n",
      "weighted avg       0.39      0.41      0.36     18528\n",
      "\n",
      "\n",
      "Test Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Decrease       0.76      0.10      0.18      2509\n",
      "    Increase       0.29      0.05      0.09      1925\n",
      "   No change       0.47      0.98      0.64      3507\n",
      "\n",
      "    accuracy                           0.48      7941\n",
      "   macro avg       0.51      0.38      0.30      7941\n",
      "weighted avg       0.52      0.48      0.36      7941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_grad_grid = GradientBoostingClassifier(learning_rate = 1, max_features = \"log2\",\n",
    "                                           min_samples_leaf = 0.4, min_samples_split =2,\n",
    "                                           n_estimators = 2)\n",
    "best_grad_grid.fit(X_train, y_train)\n",
    "best_grad_grid_pred = best_grad_grid.predict(X_test)\n",
    "print(\"Training Accuracy for default Gradient Boost \",accuracy_score(y_train,best_grad_grid.predict(X_train)))\n",
    "print(\"Test Accuracy for default Gradient Boost \",accuracy_score(y_test,best_grad_grid_pred))\n",
    "print()\n",
    "print(\"Training Classification report\\n\", classification_report(y_train,best_grad_grid.predict(X_train)))\n",
    "print()\n",
    "print(\"Test Classification report\\n\", classification_report(y_test, best_grad_grid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a considerabale improvement in accuracy using Gradient Boost Classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
